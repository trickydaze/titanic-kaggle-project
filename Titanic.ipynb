{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TITANIC SURVIVAL PREDICTION\n",
    "![titanic](./assets/titanic.gif)\n",
    "## CREATING THE DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, we need to retrieve the datasets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test= pd.read_csv('titanic/test.csv')\n",
    "train= pd.read_csv('titanic/train.csv')\n",
    "\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On the preprocessing part, we see some patterns and missing values.\n",
    "Missing values are mostly from ```Cabin``` and ```Age``` columns and also ```Age``` observations have float numbers _(e.g 34.5)_.\n",
    "I disregarded the __Cabin__, __Ticket__ ,__Sibsp__ and __Parch__ columns but you are welcome to use them to your advantage."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PREPROCESSING"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Rounding the observations to have better certainty\n",
    "train.Age=train.Age.round()\n",
    "\n",
    "# Separating features and the target\n",
    "features=['Pclass',\n",
    " 'Sex',\n",
    " 'Age',\n",
    " 'Fare',\n",
    " 'Embarked']\n",
    "target='Survived'\n",
    "\n",
    "\n",
    "\n",
    "# Label encoding the Sex column to have 0 and 1 as values\n",
    "lbl = LabelEncoder()\n",
    "\n",
    "train['Sex'] = lbl.fit_transform(train[['Sex']].values.ravel())\n",
    "test['Sex'] = lbl.fit_transform(test[['Sex']].values.ravel())\n",
    "\n",
    "# Embarked column had a few missing values, filling them\n",
    "train['Embarked'] = train['Embarked'].fillna(value=train['Embarked'].mode()[0])\n",
    "test['Embarked'] = test['Embarked'].fillna(value=test['Embarked'].mode()[0])\n",
    "train.Embarked.unique()\n",
    "\n",
    "# After missing value filling, using dummies method to encode the observations\n",
    "train_emb=pd.get_dummies(train['Embarked'])\n",
    "train_new = train[features]\n",
    "test_new = test[features]\n",
    "train_new=train_new.join(train_emb)\n",
    "train_new=train_new.drop('Embarked',axis=1)\n",
    "\n",
    "# Age column had many missing observations, this time filling them with standard deviation\n",
    "Age_stan_train = train['Age'].std()\n",
    "train['Age'] = train['Age'].fillna(value = Age_stan_train)\n",
    "Age_stan_test = test['Age'].std()\n",
    "test['Age'] = test['Age'].fillna(value = Age_stan_test)\n",
    "train.Age.isnull().sum()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# -----------------------------\n",
    "# MODEL SELECTION\n",
    "# -----------------------------\n",
    "## ~TRAIN TEST SPLIT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_train = train[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_new, y_train, test_size=0.30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "~ IMPORTANT LIBRARIES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```First Trial:\n",
    "Random Forest```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "0.7723880597014925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "params = {'n_estimators': [200,500,800,1000,1200],\n",
    "          'max_depth': [3,5,7],\n",
    "          'criterion':['entropy', 'gini']\n",
    "          }\n",
    "\n",
    "rfc_cv = GridSearchCV(rfc, params, cv = 5, n_jobs=-1, verbose=2).fit(X_train, y_train)\n",
    "pred=rfc_cv.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```Second Trial:\n",
    "XGBOOST```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[16:53:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7649253731343284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.1min finished\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "rfc = XGBClassifier()\n",
    "\n",
    "#setting the parameters\n",
    "params = {'n_estimators': [200,500,800,1000,1200],\n",
    "          'max_depth': [3,5,7],\n",
    "          'objective' : ['binary:logistic'],\n",
    "          'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "          }\n",
    "\n",
    "\n",
    "rfc_cv=RandomizedSearchCV(rfc, params, cv = 10, n_jobs=-1, verbose=2).fit(X_train, y_train)\n",
    "pred=rfc_cv.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```Third Trial:\n",
    "Gradient Boosting Classifier```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7723880597014925\n",
      "Mean Absolute Error: 0.22761194029850745\n",
      "Mean Squared Error: 0.22761194029850745\n",
      "Root Mean Squared Error: 0.47708693159476445\n"
     ]
    }
   ],
   "source": [
    "grad_clf=GradientBoostingClassifier(max_depth=4, max_features=0.3, min_samples_leaf=100,\n",
    "                           n_estimators=300)\n",
    "grad_clf.fit(X_train,y_train)\n",
    "pred=grad_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```Fourth Trial: K Neighbors Classifier```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7723880597014925\n",
      "Mean Absolute Error: 0.22761194029850745\n",
      "Mean Squared Error: 0.22761194029850745\n",
      "Root Mean Squared Error: 0.47708693159476445\n"
     ]
    }
   ],
   "source": [
    "knn= KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train,y_train)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# * BONUS\n",
    "## MIX AND MATCH : CLASSIFIER SELECTION  _(ACCURACY CONTROL)_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KNN': 0.7078511691414918, 'Logistic Regression': 0.7987967229902714, 'Random Forest': 0.8020481310803892, 'SVC': 0.6854753370882404, 'DecisionTreeClassifier': 0.7773596176821983, 'AdaBoostClassifier': 0.767400580303806, 'GradientBoostingClassifier': 0.8196705922512372, 'GaussianNB': 0.7998719918074758, 'LinearDiscriminantAnalysis': 0.7929595494111624, 'QuadraticDiscriminantAnalysis': 0.6584997439836149}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {\"KNN\": KNeighborsClassifier(),\n",
    "          \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "          \"Random Forest\": RandomForestClassifier(),\n",
    "          \"SVC\" : SVC(probability=True),\n",
    "          \"DecisionTreeClassifier\" : DecisionTreeClassifier(),\n",
    "          \"AdaBoostClassifier\" : AdaBoostClassifier(algorithm='SAMME', base_estimator=DecisionTreeClassifier(),\n",
    "                   learning_rate=1.5, n_estimators=2, random_state=7),\n",
    "          \"GradientBoostingClassifier\" : GradientBoostingClassifier(max_depth=4, max_features=0.3, min_samples_leaf=100,\n",
    "                           n_estimators=300),\n",
    "          \"GaussianNB\" : GaussianNB(),\n",
    "          \"LinearDiscriminantAnalysis\" : LinearDiscriminantAnalysis(),\n",
    "\"QuadraticDiscriminantAnalysis\" : QuadraticDiscriminantAnalysis()}\n",
    "scores={}\n",
    "cv=RepeatedStratifiedKFold(n_splits=10,n_repeats=3)\n",
    "np.random.seed(42)\n",
    "model_scores = {}\n",
    "for name, model in models.items():\n",
    "    score=cross_val_score(model,X_train,y_train,cv=cv,scoring='accuracy',n_jobs=-1)\n",
    "    scores[name]=np.mean(score)\n",
    "print(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ---------------------------------\n",
    "## The strongest prediction within the options regarding the model belongs to:\n",
    "* GradientBoostingClassifier: 0.8196705922512372\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}